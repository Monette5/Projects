{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import datetime\n",
    "import collections\n",
    "from numpy import nan as NA\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psqlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!restart refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classify bat as a specific species based on location and possibly look at the possibility that there is a species shift based \n",
    "on evolution** If I classify the species ‘bat’ into a specific species based on location data? I could have \n",
    "this as one question and the other one could be a comparison of numbers of hibernating and roosting bats to ascertain if \n",
    "they follow similar patterns to determine if some types of bats survive hibernation better than others?\n",
    "Remember to format the date as %d,%m,%y and that hib is jan/feb and roost summer months **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I also have to look at the dates and classify dates that fall outside the expected months. The months for hibernation data \n",
    "are supposed to be january and february and the roost data should be summer months mostly june and July. Can I nearest neighbours\n",
    "months or should it be classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at 3.3, 3.2, 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The intention would be to say that if a bat is spotted at a particular location, then based on the other bats spotted\n",
    "at that same location the bat is more likely to be on a specific species.** Hence task 2 will be to carry this out on both \n",
    "datasets.**\n",
    "**The question to answer on the hibernation data is how well bats survive hibernation so this needs both datasets to compare \n",
    "expected numbers found in the summer months following hibernation. However if I were to classify the bats on location for\n",
    "the roost data alone first then I could use what I learn and expand it when I am using the datatsets together.\n",
    "In this way it may be a useful way of pointing out that the results of the classification are suitable for re-use and \n",
    "having 'trained' the classifier itis now possible assume greater reliability if the results on the second dataset are \n",
    "falling within the same patterns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The locations in the roost data and field surveys are more accurate, so they require more digits in the grid reference. \n",
    "Remember that the accuracy of all the location data has been restricted to protect the bats and the privacy of property owners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the first five rows of HibernationObservations data using the head() command. Taken in Jan/Feb\n",
    "h_df = pd.read_csv('data/HibernationSurveyObservationsCleaned.csv', \n",
    "                   usecols = ['observationID','recordKey','gridReference', 'startDate','commonName'])\n",
    "h_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted dates in open refine and created a month column using value.toDate('MM/yy','MMM-yy').toString('yyyy-MM') and edit\n",
    "colum add column based on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "h_df['gridReference'].to_csv('data/gridrefs1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_df.sort_values(['recordKey'], ascending=True, inplace=True)\n",
    "h_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bat = h_df[h_df['commonName']=='Bat']\n",
    "len(bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#import dateutil\n",
    "#h_df['startDate'].apply(lambda x: dateutil.parser.parse(x,dayfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "h_df['year'] = pd.to_datetime(h_df['startDate']).dt.year\n",
    "h_df['month'] = pd.to_datetime(h_df.startDate).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Retrieving the minimum year\n",
    "minYear = h_df['year'].min()\n",
    "minYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Retrieving the maximum year\n",
    "maxYear = h_df['year'].max()\n",
    "maxYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "h_df.drop('startDate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "h_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#saving the grid refernces to csv\n",
    "h_df['gridReference'].to_csv('data/gridrefs1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#lsiting the grid references\n",
    "list(h_df['gridReference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the grid references conversion notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%run 'grid-refs-to-lat-lon.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#converting the grid refernces\n",
    "h_df['gridReference'].apply(lambda x: expand_grid_ref(to_osgb36(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#%run 'grid-refs-to-lat-lon.ipynb'\n",
    "h_df['test'] = h_df['gridReference'].apply(lambda x: expand_grid_ref(to_osgb36(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "h_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing to csv\n",
    "h_df.test.to_csv('data/refs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lising the grid refs\n",
    "hrefs = []\n",
    "for v in h_df.test:\n",
    "     hrefs.append(v)\n",
    "print(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#ptting then references into a dataframe\n",
    "ref_df = pd.DataFrame(h_df.test)\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#removing the extra column\n",
    "h_df.drop('test', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing back to csv\n",
    "ref_df.to_csv('data/hibrefs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the first five rows of RoostSurveyObservations data using the head() command. This is cleaned data from open refine\n",
    "# The comparisons can be seen below where I had determined the grid references which couldn't be converted and I removed them using\n",
    "#a text facet. I have left the exploration in to show the steps taken.\n",
    "rCleaned_df = pd.read_csv('data/RoostObservationsCleaned1.csv', \n",
    "                   usecols = ['observationID','recordKey','gridReference', 'startDate','commonName'])\n",
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Extracting first 4 digits to convert so that the entries are the same format as the hibernation data.\n",
    "rCleaned_df['gridReference'] = rCleaned_df['gridReference'].str[0:4]\n",
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the full dataframes to open refine and take out all the rows not equal to 'bat' then remove all columns except\n",
    "latitude and longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rCleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#converting dates\n",
    "rCleaned_df['startDate'] = pd.to_datetime(rCleaned_df['startDate'])\n",
    "rCleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#extracting month and year\n",
    "rCleaned_df['year'] = rCleaned_df['startDate'].dt.year\n",
    "rCleaned_df['month'] = rCleaned_df.startDate.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#sorting based on recordKey \n",
    "rCleaned_df.sort_values(['recordKey'], ascending=True, inplace=True)\n",
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#dropping the startDate column\n",
    "rCleaned_df.drop('startDate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#reading in the coordinates\n",
    "roostCoords = pd.read_csv('data/roostcoords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#putting the coordinates columns into the dataframes\n",
    "rCleaned_df['Coords'] = roostCoords.Coords\n",
    "rCleaned_df['Coords1'] = roostCoords.Coords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing it to csv\n",
    "rCleaned_df.to_csv('data/RoostCoords.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#finding the minimum year\n",
    "rCleaned_df.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#maximum  year\n",
    "rCleaned_df.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#adding a test column\n",
    "rCleaned_df['test'] = rCleaned_df['gridReference'].apply(lambda x: to_osgb36(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for the 'problem' grid refernces by using comparisons with the correct ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#looking at the hibernation refs\n",
    "grid = list(h_df.gridReference.str[0:2])\n",
    "hrefs = []\n",
    "for v in grid:\n",
    "     hrefs.append(v)\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#looking at the roost refs\n",
    "grids = list(rCleaned_df.gridReference.str[0:2])\n",
    "crefs = []\n",
    "for v in grids:\n",
    "    crefs.append(v)\n",
    "print(crefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the refernces that are not in the hibernation dataset so that they can be removed from the roost dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#finding the references to be removed\n",
    "unlike = []\n",
    "for value in hrefs:\n",
    "    if value not in crefs:\n",
    "        if value not in unlike:\n",
    "            unlike.append(value)\n",
    "unlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing grid refs to csv \n",
    "rCleaned_df['gridReference'].to_csv('data/roostrefs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing test column to csv\n",
    "rCleaned_df.test.to_csv('data/roostrefs1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#listing hibernation names\n",
    "aList = pd.unique(h_df.commonName)\n",
    "aList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#listing roost names\n",
    "anotherList = pd.unique(rCleaned_df.commonName)\n",
    "anotherList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#making a copy to keep the original intact\n",
    "hib_df = h_df.copy()\n",
    "\n",
    "Notcommon = []\n",
    "for value in aList:\n",
    "    if value not in anotherList:\n",
    "        if value not in Notcommon:\n",
    "            Notcommon.append(value)\n",
    "Notcommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#checking the common values of commonname over the roost and hibernation datasets\n",
    "aSet = set(rCleaned_df.commonName).intersection(h_df.commonName)\n",
    "aSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#checking the common values of commonname over the roost and hibernation datasets\n",
    "anotherSet = set(h_df.commonName)\n",
    "anotherSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#dropping those not in both\n",
    "dropList = ['Myotis Bat species','Western Barbastelle','Mouse-eared Bat','Long-eared Bat species','Lesser Noctule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#dropping those not in both\n",
    "deleted_data = hib_df.loc[hib_df['commonName'].isin(dropList)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amending the hibernation data to have the same bat types as the roost data. I performed this in\n",
    "order to run the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Amending the hibernation data to have the same bat types as the roost data. I performed this in\n",
    "#order to run the classifier.\n",
    "retained_data = hib_df.loc[~hib_df['commonName'].isin(dropList)]\n",
    "pd.unique(retained_data['commonName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end the grid references had to be converted using an external source. The notebook provided very unreliable results\n",
    "and I used the site - http://gridreferencefinder.com/batchConvert/batchConvert.php instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the first five rows of data using the head() command.\n",
    "coord_df = pd.read_csv('data/latlong.csv')\n",
    "len(coord_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#adding the latitude and longitude columns\n",
    "retained_data['latitude'] = coord_df.Latitude\n",
    "retained_data['longitude'] = coord_df.Longitude\n",
    "retained_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "list(retained_data.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing the new dataframe to csv\n",
    "retained_data.to_csv('data/HibernationCleaned10.csv', index=False) #Add to txt and dat and put in database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipistrelles are our most common bats, but we don’t know where they all go in winter! We have not found enough hibernation\n",
    "roosts to account for the numbers we see in the summer months.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the first five rows of data using the head() command.\n",
    "coord1_df = pd.read_csv('data/RoostLatLong.csv')\n",
    "len(coord1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#adding the latitude and longitude columns\n",
    "rCleaned_df['latitude'] = coord1_df.Latitude\n",
    "rCleaned_df['longitude'] = coord1_df.Longitude\n",
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#removing the test column\n",
    "rCleaned_df.drop('test', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#writing the new dataframe to csv\n",
    "rCleaned_df.to_csv('data/RoostCleaned10.csv', index=False) #Add to txt and dat and put in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#reading the coordinates to a dataframe\n",
    "coordsh_df = pd.read_csv('data/hibcoords.csv')\n",
    "len(coordsh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#adding the coords columns\n",
    "retained_data['Coords'] = coordsh_df.Coords\n",
    "retained_data['Coords1'] = coordsh_df.Coords1\n",
    "#This exploration didn't go far ad it was to try an alternative to latitude nad longitude for conversion purposes. \n",
    "#It didn't gain anything though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I moved the SQL exploration to the PostrgreSQL notebook - EMA/PostgreSQL_DB.ipynb. I also used a method to read in the data\n",
    "from dataframes rather than from the csv files I used initially.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was really tricky, to read in the csv files I had to change the file extensions to .txt and open them in excel in order\n",
    "to deliminate the columns sufficiently for it to be read into postgreSQL. I then changed the extension to.dat to read it in\n",
    "as data so that postgre could read it and parse it to the correct columns.\n",
    "I had cleaned the GRID reference columns using a combination of removing the Irish rerefences in Open Refine by using a Text \n",
    "Facet and deleting the rows with those grid references and I then removed the 5 character references by cutting it down to four\n",
    "character references. I would assume that this was carried out by the Bat Conservation Trust on the Hibernation Data and that \n",
    "is why they were already 4 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The remaining exploration can be found in the postgreSQL, Maps, Classified Analysis and KNN notebooks in the EMA folder **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://test:test@localhost:5432/tm351test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS HibernationBats;\n",
    "CREATE TABLE HibernationBats(\n",
    "    observationID VARCHAR(30),\n",
    "    recordKey VARCHAR(30),\n",
    "    gridReference VARCHAR(30),\n",
    "    commonName VARCHAR(70),\n",
    "    year VARCHAR(30),\n",
    "    month VARCHAR(30),\n",
    "    latitude VARCHAR(30),\n",
    "    longitude VARCHAR(30),\n",
    "    PRIMARY KEY (observationID)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# iterate over the dataframe 'df' & insert each row into the hibernation table\n",
    "for index, row in retained_data.iterrows():\n",
    "    observationID = row['observationID']\n",
    "    recordKey = row['recordKey']\n",
    "    gridReference = row['gridReference']\n",
    "    commonName = row['commonName']\n",
    "    year = row['year']\n",
    "    month = row['month']\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    %sql INSERT into HibernationBats VALUES(:observationID, :recordKey, :gridReference, :commonName, :year, :month, :latitude, :longitude);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql SELECT * FROM HibernationBats\n",
    "WHERE HibernationBats.commonName = 'Lesser Horseshoe Bat' AND HibernationBats.year = '2013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql SELECT * FROM HibernationBats\n",
    "WHERE HibernationBats.commonName = 'Bat';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "conn = pg.connect(dbname='tm351test', host='localhost', user='test', password='test', port=5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "batonly = pd.read_sql_query(\"SELECT * FROM HibernationBats\\nWHERE HibernationBats.commonName = 'Bat';\",conn)\n",
    "batonly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dfh = pd.read_sql_query('select * from HibernationBats',conn)\n",
    "dfh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS RoostBats CASCADE;\n",
    "CREATE TABLE RoostBats(\n",
    "    observationID VARCHAR(30),\n",
    "    recordKey VARCHAR(30),\n",
    "    gridReference VARCHAR(30),\n",
    "    commonName VARCHAR(70),\n",
    "    year VARCHAR(30),\n",
    "    month VARCHAR(30),\n",
    "    latitude VARCHAR(30),\n",
    "    longitude VARCHAR(30),\n",
    "    PRIMARY KEY (observationID)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# iterate over the dataframe 'df' & insert each row into the hibernation table\n",
    "for index, row in rCleaned_df.iterrows():\n",
    "    observationID = row['observationID']\n",
    "    recordKey = row['recordKey']\n",
    "    gridReference = row['gridReference']\n",
    "    commonName = row['commonName']\n",
    "    year = row['year']\n",
    "    month = row['month']\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    %sql INSERT into RoostBats VALUES(:observationID, :recordKey, :gridReference, :commonName, :year, :month, :latitude, :longitude);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dfr = pd.read_sql_query('select * from RoostBats',conn)\n",
    "dfr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Have to bring in the file to excel after saving the csv with .txt extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM RoostBats\n",
    "WHERE RoostBats.commonName = 'Bat';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql SELECT * FROM RoostBats\n",
    "WHERE RoostBats.latitude = '51.217579';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "roostbatonly = pd.read_sql_query(\"SELECT * FROM RoostBats\\nWHERE RoostBats.commonName = 'Bat';\",conn)\n",
    "roostbatonly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You test it by witholding some of the data which has known classes (of what you are trying to classify)\n",
    "Run the classifier on this test data to see if you get the correct classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting latitude and longitude for commonName 'BAT' in order to classify correctly. I will start with ROOSTBATS now use\n",
    "the results of the classification to re-classify the hibernation bats.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Predict all the ones where they have the common name 'bat' by reading in the latitude and longitude to the test dataframe\n",
    "Find out how to put the results of the select into a dtafram and then put all the lat and lon ino the test df for name bat.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hibatitude_df = pd.read_csv('data/HibernationBatitude.csv')\n",
    "len(hibatitude_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lat = list(hibatitude_df['latitude'])\n",
    "long = list(hibatitude_df['longitude'])\n",
    "print(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "robintude_df = pd.read_csv('data/RoostBatitude.csv')\n",
    "robintude_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "Rlat = list(robintude_df['latitude'])\n",
    "Rlong = list(robintude_df['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN = KNeighborsClassifier(n_neighbors=4, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#training_df = retained_data[['year', 'latitude', 'longitude']]\n",
    "#targetV_ss = retained_data['commonName']\n",
    "\n",
    "#classifier_3NN.fit(training_df, targetV_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "retained_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "retained_data.to_csv('data/HibernationCoords.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "nobats = retained_data.loc[retained_data['commonName'] != 'Bat']\n",
    "nobats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#selecting columns which don't have bat to set test data\n",
    "nobat = dfr.loc[dfr['commonname'] != 'Bat']\n",
    "nobat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "nobath = dfh.loc[dfh['commonname'] != 'Bat']\n",
    "nobath.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#testData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#output_df = testData_df.copy()\n",
    "#output_df['commonName'] = classifier_3NN.predict(testData_df)\n",
    "\n",
    "#output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use this method**notebook 20.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****http://jncc.defra.gov.uk/page-4271****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****http://www.bio.bris.ac.uk/research/bats/britishbats/****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**use this method - Try putting a 'bat into the classifier by putting it in it's own dataframe and see where it puts it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "training_df1 = nobats[['Coords', 'Coords1']]\n",
    "targetV_ss1 = nobats['commonName']\n",
    "\n",
    "classifier_3NN.fit(training_df1, targetV_ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Hibernation\n",
    "#'year':[1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013],\n",
    "#To classify several instances at once, we use more rows in the test data DataFrame:\n",
    "testData_df1=pd.DataFrame({'latitude':[53.217612,52.125155,53.047173,51.049767,51.313717,53.404438,51.217579,50.337666,51.139625,\n",
    "                                       53.404438,50.51745,51.049767,55.920472,50.883962,51.313717,51.246002,51.608482,55.113482],\n",
    "                'longitude':[-3.499085,0.33584239,-1.8522842,0.13863303,0.43789052,-2.7535372,0.71922612,-3.6875961,0.14278336,\n",
    "                             -2.4718348,-2.7535372,-3.6940008,0.13863303,-2.8016146,-0.86412773,\n",
    "                             0.43789052,-2.8609895,-1.7125865]},columns = ['latitude','longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "testData_df1=pd.DataFrame({'Coords':[590000,610000,350000,330000,330000,200000,170000,160000,580000,\n",
    "                                       180000,280000,550000,440000,430000,220000,480000,410000,260000],\n",
    "                'Coords1':[150000,150000,390000,370000,400000,50000,50000,20000,240000,\n",
    "                             60000,70000,160000,210000,220000,70000,\n",
    "                             330000,350000,310000]},columns = ['Coords', 'Coords1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_df1 = testData_df1.copy()\n",
    "output_df1['commonName'] = classifier_3NN.predict(testData_df1)\n",
    "\n",
    "output_df1\n",
    "#use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "testData_df3 = pd.DataFrame({'Coords':[350000],\n",
    "                            'Coords1':[390000]})\n",
    "testData_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(testData_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql SELECT * FROM HibernationBats\n",
    "WHERE HibernationBats.latitude = '51.217579';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Bat commonname combined.\n",
    "batframes = [batonly, roostbatonly]\n",
    "combined_bat = pd.concat(batframes)\n",
    "combined_bat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "training_df = nobat[['latitude', 'longitude']]\n",
    "targetV_ss = nobat['commonname']\n",
    "\n",
    "classifier_3NN.fit(training_df, targetV_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Roost\n",
    "#To classify several instances at once, we use more rows in the test data DataFrame:\n",
    "testData_df=pd.DataFrame({'latitude':[51.217579,53.047173,51.21058,51.787235,53.404438,51.496237,51.049767,50.337666,\n",
    "                                      52.029198,55.113482,51.967043,53.217612,51.303973,51.842687,51.321883],\n",
    "                 'longitude':[0.71922612,-1.8522842,1.0052037,-1.4215015,-2.7535372,-4.6503679,0.13863303,-3.6875961,\n",
    "                             0.62241505,-2.4718348,-1.4191904,-3.499085, 0.86781568,-4.9047531,0.007744095]},\n",
    "                             columns = ['latitude','longitude'])\n",
    "testData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_df = testData_df.copy()\n",
    "output_df['commonname'] = classifier_3NN.predict(testData_df)\n",
    "\n",
    "output_df\n",
    "#use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "testData_df2 = pd.DataFrame({'latitude':[51.953250],\n",
    "                            'longitude':[-3.893114]})\n",
    "testData_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(testData_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#make these all bats\n",
    "a=pd.DataFrame({'latitude':[51.214167],'longitude':[0.86222925]})\n",
    "b=pd.DataFrame({'latitude':[51.117035],'longitude':[1.1420372]})\n",
    "c=pd.DataFrame({'latitude':[51.506201],'longitude':[-0.27236048]})\n",
    "d=pd.DataFrame({'latitude':[52.591922],'longitude':[-0.82048441]})\n",
    "e=pd.DataFrame({'latitude':[54.663503],'longitude':[-1.381404]})\n",
    "f=pd.DataFrame({'latitude':[51.234384],'longitude':[-0.13931546]})\n",
    "g=pd.DataFrame({'latitude':[51.316615],'longitude':[0.29453105]})\n",
    "h=pd.DataFrame({'latitude':[51.40919],'longitude':[0.15536344]})\n",
    "i=pd.DataFrame({'latitude':[52.047487],'longitude':[-0.39739304]})\n",
    "j=pd.DataFrame({'latitude':[51.959501],'longitude':[-0.54607466]})\n",
    "k=pd.DataFrame({'latitude':[51.781437],'longitude':[-0.69677119]})\n",
    "l=pd.DataFrame({'latitude':[51.961208],'longitude':[-0.69156481]})\n",
    "m=pd.DataFrame({'latitude':[53.303364],'longitude':[-0.20068364]})\n",
    "n=pd.DataFrame({'latitude':[51.787235],'longitude':[-1.4215015]})\n",
    "o=pd.DataFrame({'latitude':[51.863445],'longitude':[-0.11347092]})\n",
    "p=pd.DataFrame({'latitude':[51.153675],'longitude':[-0.85751944]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql SELECT * FROM RoostBats\n",
    "WHERE RoostBats.latitude = '51.781437';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To see how well the classifier is working, we can plot the test data on the same axes as the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifier_3NN.predict(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the results it can be seen that it is possible to predict the type of bat using the k-nn classifier. I experimented with \n",
    "using 'year', but the results appeared to be the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#hibernation value counts\n",
    "dfh.commonname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#roost value counts\n",
    "dfr.commonname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#combined value counts\n",
    "comb = [dfh, dfr]\n",
    "comb_bat = pd.concat(comb)\n",
    "comb_bat.commonname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These cells have to be run prior to manipulation of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bat_size = h_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bat_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Select from DataFrame using criteria from multiple columns\n",
    "newdf = df[(df['column_one']>2004) & (df['column_two']==9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ford_winter_manufacturing_df = \n",
    "ford_manufacturing_df[ (ford_manufacturing_df['Month'] <= 2) |\n",
    "                      (ford_manufacturing_df['Month'] >= 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ford_manufacturing_df.query('Month<=2 or Month>=11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bat_size = bat_size[bat_size['startDate'] >=2000][['startDate','commonName']]\n",
    "bat_size = bat_size[bat_size['startDate'] <2014][['startDate','commonName']]\n",
    "bat_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.unique(h_df['commonName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "groupeddata = bat_size.groupby(['commonName'])\n",
    "grouped = groupeddata['commonName'].aggregate('count')\n",
    "groupeddata.size()\n",
    "#experimenting with grouping to try to get a sutable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "totals = groupeddata.sum()\n",
    "grouped.plot(kind='bar')\n",
    "plt.title('Total Hibernating Bats', fontsize=20, color='Blue')\n",
    "plt.xlabel('Bat Name')\n",
    "plt.ylabel('Total Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hib_df = bat_size.copy()\n",
    "#Making a copy of the dataframe to keep the previous analysis intact.\n",
    "hib_df = hib_df[['commonName','startDate']]\n",
    "hib_df['Count'] = hib_df['startDate'].map(hib_df.groupby(['startDate'])['commonName'].unique().apply(len))\n",
    "hib_df = hib_df.rename(columns={'startDate': 'year'})\n",
    "#created a new dataframe with selected columns in order to show the relevant data to see the bat counts over time.\n",
    "hib_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "new_year = hib_df.groupby(['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "new_year_totals = new_year.sum()\n",
    "new_year_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "new_year_totals.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#bat_size['Count'] = bat_size['year'].map(bat_size.groupby(['year'])['commonName'].unique().apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#bat_size.groupby(['year', 'commonName'])[['Count']].sum()\n",
    "#bat_size.reset_index()\n",
    "#bat_size.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#bat_df = h_df[['commonName','startDate']]\n",
    "#pivoted = bat_df.pivot_table(index=['commonName'], aggfunc='count')\n",
    "#pivoted.reset_index('startDate',inplace=True)\n",
    "#pivoted = pivoted.rename(columns = {'startDate' : 'count'})\n",
    "#pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualising by counts of bats\n",
    "#pivoted.plot.bar(x=['commonName'])\n",
    "#plt.title('Total Bats', fontsize=20, color='Blue')\n",
    "#plt.xlabel('Bat Name')\n",
    "#plt.ylabel('Total Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the first five rows of FieldSurveyObservations data using the head() command. Summer months\n",
    "#f_df = pd.read_csv('data/FieldSurveyObservations.csv', \n",
    "                   #usecols = ['observationID','recordKey','gridReference', 'startDate','commonName'])\n",
    "#f_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#f_df.commonName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#f_df['year'] = pd.to_datetime(f_df['startDate']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#syear = f_df.year.min()\n",
    "#syear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#eyear = f_df.year.max()\n",
    "#eyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify bats using grid references\n",
    "There are thousnds of entries of bats but only 21 species in the hibernation data and 17 in the roost data.\n",
    "The predicted attribute is the bat which is one of the 20 species other than 'bat'.\n",
    "\n",
    "The remaining data can be split into training and test datasets and the results can be used to evaluate the algorithm implememtation.\n",
    "\n",
    "Good accuracy using this method can be over 90%.\n",
    "\n",
    "'Steps:\n",
    "1.Handle Data: Open the dataset from CSV and split into test/train datasets.\n",
    "2.Similarity: Calculate the distance between two data instances.\n",
    "3.Neighbors: Locate k most similar data instances.\n",
    "4.Response: Generate a response from a set of data instances.\n",
    "5.Accuracy: Summarise the accuracy of predictions.\n",
    "6.Main: Tie it all together.'(Brownlee, J, 2014) - http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Reading in the first five rows of RoostSurveyObservations data using the head() command. Summer months\n",
    "r_df = pd.read_csv('data/RoostObservations.csv', \n",
    "                   usecols = ['observationID','recordKey','gridReference', 'startDate','commonName'])\n",
    "r_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bats = r_df[r_df['commonName']=='Bat']\n",
    "len(bats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Step 2.Next we need to split the data into a training dataset that kNN can use to make predictions and a test dataset that \n",
    "#we can use to evaluate the accuracy of the model.\n",
    "#We first need to convert the flower measures that were loaded as strings into numbers that we can work with. \n",
    "#Next we need to split the data set randomly into train and datasets. A ratio of 67/33 for train/test is a standard ratio used.\n",
    "#Pulling it all together, we can define a function called loadDataset that loads a CSV with the provided filename and splits \n",
    "#it randomly into train and test datasets using the provided split ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rCleaned_df.sort_values(['recordKey'], ascending=True, inplace=True)\n",
    "rCleaned_df.gridReference.fillna(method = 'ffill', inplace = True)\n",
    "rCleaned_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ref1 = []\n",
    "for v in rCleaned_df.gridReference:\n",
    "     ref1.append(v)\n",
    "print(ref1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rec1 = []\n",
    "for v in rCleaned_df.recordKey:\n",
    "    if v not in rec1:\n",
    "        rec1.append(v)\n",
    "len(rec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rCleaned_df['two']= rCleaned_df.gridReference.apply(lambda x: (x[0]+x[1]))\n",
    "rCleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ref2 = []\n",
    "for v in rCleaned_df.gridReference:\n",
    "     ref2.append(v)\n",
    "print(ref2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ref3 = []\n",
    "for v in h_df.gridReference:\n",
    "    if v not in ref3:\n",
    "         ref3.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "reftwo = []\n",
    "for v in rCleaned_df.two:\n",
    "    if v not in reftwo:\n",
    "          reftwo.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "regions = pd.read_csv('data/regions.csv')\n",
    "regions.regions[21] = 'NA'\n",
    "regions.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#regions is the list of regions in the conversion function notebook.\n",
    "regList = []\n",
    "for v in regions.regions:\n",
    "    regList.append(v)\n",
    "regList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#These are the values to be removed\n",
    "new_list = []\n",
    "for element in reftwo:\n",
    "    if element not in regList:\n",
    "        new_list.append(element)\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for element in new_list:\n",
    "        if element not in regList:\n",
    "            regList.append(element)\n",
    "regList\n",
    "#Use this as the regions to convert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**I will add these grid references to the region list and see what happens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "set(reftwo).intersection(regList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "listone = []\n",
    "for v in regions.regions:\n",
    "    listone.append(v)\n",
    "listone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "listtwo = []\n",
    "for v in rCleaned_df.two:\n",
    "    listtwo.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "listfour = []\n",
    "for v in r_df.four:\n",
    "    listfour.append(v)\n",
    "listfour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "newone = []\n",
    "v = listone\n",
    "x = listtwo\n",
    "for i in x:\n",
    "    for j in v:\n",
    "        if i != j:\n",
    "            newone.append(j)\n",
    "newone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for v in rec1:\n",
    "    if v[:2] in regions:\n",
    "        test.append(v)\n",
    "print(test)\n",
    "#lambda x: False if x[:2] in regions else True)\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%run 'grid-refs-to-lat-lon.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#rCleaned_df['four'].apply(lambda x: to_osgb36(x))#This was used initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rCleaned_df.commonName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(pd.unique(h_df.commonName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#print(len(pd.unique(f_df.commonName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(pd.unique(rCleaned_df.commonName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(h_df),len(rCleaned_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "groupedroost = rCleaned_df.groupby(['commonName'])\n",
    "groupedr = groupedroost['commonName'].aggregate('count')\n",
    "groupedroost.size()\n",
    "#experimenting with grouping to try to get a sutable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "roost_size = rCleaned_df.copy()\n",
    "roost_size = roost_size[roost_size['startDate'] >=2000][['startDate','commonName']]\n",
    "roost_size = roost_size[roost_size['startDate'] <2014][['startDate','commonName']]\n",
    "roost_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "totals = groupedroost.sum()\n",
    "groupedr.plot(kind='bar')\n",
    "plt.title('Total Roosting Bats', fontsize=20, color='Blue')\n",
    "plt.xlabel('Bat Name')\n",
    "plt.ylabel('Total Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rsyear = rCleaned_df.startDate.min()\n",
    "rsyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "reyear = rCleaned_df.startDate.max()\n",
    "reyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#f_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.unique(h_df.commonName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#rCleaned_df.gridReference.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/roostrefs-csv.csv', usecols =['gridRef'])\n",
    "df\n",
    "#df['gridRef'] = df['gridRef'].apply(lambda x: int(str(x)))\n",
    "#df['test'] = df['gridRef'].apply(lambda x: to_osgb36(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'A good way of using k-NN might be for cross validation (see Part 20, section 3.4 and notebook 20.2). So if you had some data you thought might make a good classifier, you could adapt the code in notebook 20.2 to investigate what the best value of k would be for that classifier, and the results would also give you a feel for how good the classifier would be (maybe you'll find that some features work better than others).\n",
    "\n",
    "Alternatively, for the example you've given, you might investigate whether a classifier trained on the first nine years works as well on the second nine years as the first. That might tell you something about whether longer term predictions based on the earlier data would be reliable.\n",
    "\n",
    "A different use of k-NN can be to fill gaps in one or more datasets. For example, if you have some gaps in dataset 1, but another dataset 2 which covers a similar range, then you can try to build a classifier using dataset 2 to try to fill the gaps in dataset 1.\n",
    "\n",
    "As is discussed later in the thread, in TM351 we're not looking for great revelations, rather that you demonstrate your ability to apply the techniques rigorously, and to be able to make a good critique of your results.'\n",
    "(TM351 Tutorial, 2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.unique(rCleaned_df['commonName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Checking that startDate and endDate are equal(they are so the column will now be date)\n",
    "#daterange = h_df['endDate'] - h_df['startDate']\n",
    "#daterange.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bat_df = rCleaned_df[['commonName','startDate']]\n",
    "pivoted = bat_df.pivot_table(index=['commonName'], aggfunc='count')\n",
    "pivoted.reset_index('startDate',inplace=True)\n",
    "pivoted = pivoted.rename(columns = {'startDate' : 'count'})\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualising by counts of bats\n",
    "pivoted.plot.bar(x=['commonName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "new_df = rCleaned_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# We need to define the function, over the specific columns of the group, \n",
    "# so it will act as the filter function - i.e. return true or false:\n",
    "filter_average_mark_over_50 = lambda x: (x['Mark'].mean() > 50)\n",
    "groupeddata.filter(filter_average_mark_over_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# First a simple function to convert months to seasons\n",
    "def month_to_season(month):\n",
    "    season='Winter'\n",
    "    if month in [2,3,4]:\n",
    "        season='Spring'\n",
    "    elif month in [5,6,7]:\n",
    "        season='Summer'\n",
    "    elif month in [8,9,10]:\n",
    "        season='Autumn'\n",
    "    return season\n",
    "# Now add a column to salesbook using the pandas.apply to apply the new \n",
    "# function to the Month column:\n",
    "salesbook_df['Season'] = salesbook_df['Month'].apply(month_to_season)\n",
    "# Check to see it had the desired affect:\n",
    "salesbook_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#new_df = new_df[['commonName','startDate','gridReference']]\n",
    "#new_df['Count'] = new_df['startDate'].map(new_df.groupby(['startDate'])['commonName'].unique().apply(len))\n",
    "#new_df = new_df.rename(columns={'startDate': 'year'})\n",
    "#new_df['year'] = new_df.year.dt.year#changed to years\n",
    "#created a new dataframe with selected columns in order to show the relevant data to see the bat counts over time.\n",
    "#new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM  this_year JOIN last_year ON (student = name) AND (course = module);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM member FULL OUTER JOIN payment_made ON member.name = payment_made.name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([sample1_df, sample2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Looking at the population of the common name Bat over time.\n",
    "bat = new_df[new_df['commonName']=='Bat']\n",
    "grp = bat.groupby('startDate').apply(lambda x: x['commonName'].value_counts()).unstack().fillna(0)\n",
    "grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Grouping as a dataframe\n",
    "b = bat.groupby(['startDate', 'commonName'])[['count']].sum()\n",
    "bs = b.reset_index()\n",
    "bs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bs.plot(x='year', kind='bar', figsize=(10,10))\n",
    "plt.title('Common Name \"Bat\"', fontsize=20, color='Red')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Count')\n",
    "#bat.plot(x=['years'], y=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Using pivot to reorder to plot without specifying the axis\n",
    "bats = bs.pivot(index='year', columns='commonName').fillna(0)\n",
    "bats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bats.plot(kind='bar', figsize=(10,10))\n",
    "plt.title('Common Name \"Bat\"', fontsize=20, color='Red')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Count')\n",
    "#bat.plot(x=['years'], y=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Looking at the population of the common name Natterer's Bat over time.\n",
    "natbat = new_df[new_df['commonName']=='Natterer\\'s Bat']\n",
    "#g = natbat.groupby('years').apply(lambda x: x['commonName'].value_counts()).unstack().fillna(0)\n",
    "#g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Grouping by years and commonName\n",
    "nb = natbat.groupby(['year', 'commonName'])[['Count']].sum()\n",
    "bn = nb.reset_index()\n",
    "bn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Pivot to reorder as before\n",
    "batnat = bn.pivot(index='year', columns='commonName').fillna(0)\n",
    "batnat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Plotting pivot because no need to specify axis\n",
    "batnat.plot(kind='bar', figsize=(10,10))\n",
    "plt.title('Common Name \"Natterer\\'s Bat\"', fontsize=20, color='Red')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# The crosstab has reshaped the DataFrame - there is now a row for each unique value in the commonNmae column \n",
    "#of the original table, and a column for each unique value in the years column of the original table.\n",
    "#At the intersection of each row and column there is the count of the number of times that row value and that column \n",
    "#value occur in the original table's rows.\n",
    "# The result is a table bats_df.\n",
    "bats_df = pd.crosstab(new_df['commonName'], new_df['year'], margins=True)\n",
    "#bats_df.reset_index()\n",
    "bats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pivoted = new_df.pivot_table(index=['commonName', 'year', 'Count'], aggfunc=np.sum)\n",
    "pivoted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Adding functions to select years\n",
    "updated_bats = new_df.copy()\n",
    "#if pnl[company].tail(1)['Active'].any()==1:\n",
    "    #print 'yay'\n",
    "def select_decade(y):\n",
    "    for y in updated_bats.year:\n",
    "        if y.all() > 1960:\n",
    "            return year\n",
    "def floor_decade(y):\n",
    "    for y in updated_bats.year:\n",
    "        return (y // 10) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "updated_bats['year'] = (updated_bats['year']// 10) * 10\n",
    "grouped = updated_bats.groupby(['year'])\n",
    "batter_df = grouped['commonName', 'Count'].aggregate('sum')\n",
    "batter_df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "battier = updated_bats.groupby(['year', 'commonName'])[['Count']].sum()\n",
    "#battier.replace(np.nan, 0)\n",
    "battier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "battiest = battier.reset_index()\n",
    "battiest.head()\n",
    "battiest.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "counts = battiest.groupby('year').apply(lambda x: x['commonName'].value_counts()).unstack().fillna(0)\n",
    "counts            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "count = battiest.pivot(index='year', columns='commonName').fillna(0)\n",
    "count.reset_index()\n",
    "count.columns\n",
    "\n",
    "count.plot(kind='bar', figsize=(20,20))\n",
    "plt.title('Bat Population of the UK over time, by decade', fontsize=20, color='Blue')\n",
    "plt.xlabel('Years by decade')\n",
    "plt.ylabel('Total Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Concatenating\n",
    "batframes = [h_df, r_df]\n",
    "results = pd.concat(batframes).fillna(0)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the weather data over the period and concatenating it.\n",
    "london_df = pd.read_csv('data/LondonWeatherdata/LondonWeather2005.csv', usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])\n",
    "london_df1 = pd.read_csv('data/LondonWeatherdata/LondonWeather2010.csv', usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])\n",
    "london_df2 = pd.read_csv('data/LondonWeatherdata/LondonWeather2015.csv', usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Concatenating\n",
    "frames = [london_df, london_df1, london_df2]\n",
    "result = pd.concat(frames).fillna(0)\n",
    "result['GMT']= pd.to_datetime(result['GMT']).dt.year\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Grouping to plot\n",
    "result_grouped = result.groupby(['GMT'])['Mean TemperatureC','Precipitationmm'].mean()\n",
    "result_grouped.plot.bar(subplots=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the weather data over the period and concatenating it.\n",
    "leeds_df = pd.read_csv('data/LeedsWeatherdata/LeedsWeather2001.csv', usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])\n",
    "leeds_df1 = pd.read_csv('data/LeedsWeatherdata/LeedsWeather2009.csv', usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])\n",
    "leeds_df2 = pd.read_csv('data/LeedsWeatherdata/LeedsWeather2015.csv', usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Concatenating\n",
    "frames1 = [leeds_df, leeds_df1, leeds_df2]\n",
    "result1 = pd.concat(frames1).fillna(0)\n",
    "result1['GMT']= pd.to_datetime(result1['GMT']).dt.year\n",
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Grouping to plot\n",
    "result1_grouped = result1.groupby(['GMT'])['Mean TemperatureC','Precipitationmm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#plotting Leeds weather fropm 1996 - 2015\n",
    "result1_grouped.plot.bar(subplots=True, figsize=(10,10), color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading in the weather data over the period and concatenating it.\n",
    "Manch_df = pd.read_csv('data/ManchesterWeatherdata/ManchesterWeather2001.csv', \n",
    "                       usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])\n",
    "Manch_df1 = pd.read_csv('data/ManchesterWeatherdata/ManchesterWeather2009.csv', \n",
    "                        usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])\n",
    "Manch_df2 = pd.read_csv('data/ManchesterWeatherdata/ManchesterWeather2015.csv', \n",
    "                        usecols = ['GMT', 'Mean TemperatureC', 'Precipitationmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Concatenating\n",
    "frames2 = [Manch_df, Manch_df1, Manch_df2]\n",
    "result2 = pd.concat(frames2).fillna(0)\n",
    "result2['GMT']= pd.to_datetime(result2['GMT']).dt.year\n",
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Grouping to plot\n",
    "result2_grouped = result2.groupby(['GMT'])['Mean TemperatureC','Precipitationmm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#plotting Leeds weather fropm 1996 - 2015\n",
    "result2_grouped.plot.bar(subplots=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ax = result_grouped.plot.bar()\n",
    "result1_grouped.plot.bar(ax=ax, figsize=(15,10), color='white')\n",
    "plt.title('London and Leeds weather over time from 2001 to 2015', fontsize=20, color='Blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Having studied the weather data over the period it can be seen that there is a peak in temperature in 2005 for both Leeds and\n",
    "London, although the weather mean temperature in London is higher overall. It can also be seen that at the same time as the\n",
    "temperature increased so did the precipitation. It appears that bats must like warm temperatures though because the \n",
    "overall bat population increased in line with the temperature increases, however they may not be big fans of rain because the \n",
    "populations are decreasing in line with the increases in precipitation. I attempted to plot Cardiff, Manchester and Bristol data, \n",
    "but apparently it didn't rain over the period which I think is highly unlikely. However they followed the same temperature trends \n",
    "as London and Leeds. There was also the issue of no records for weather for earlier years which made the results a guide only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# The create_map() saves an HTML representation of the map object to the specified file.\n",
    "# (You can open this file in your browser as well as it displaying directly in the Notebook.)\n",
    "# This will not display a map if your are offline. A network connection is required to \n",
    "# retrieve the map tiles.\n",
    "\n",
    "# Once you've run this cell, and the map is rendered below, you'll see, \n",
    "# if you put your mouse over it and scroll, that it is zoomable.\n",
    "\n",
    "map_TMA = folium.Map(location=[55.3781,3.4360], width=960, height=500, zoom_start=5, max_zoom=16)\n",
    "\n",
    "map_TMA.create_map(path='data/TMA.html')\n",
    "\n",
    "#  Due to a bug in the current version of folium, the following line is needed to force\n",
    "#  the named map to be displayed in the output cell. \n",
    "map_TMA.render_iframe = True\n",
    "\n",
    "# This is the standard Notebook way of displaying the last object named in the cell.\n",
    "# It's a map object.\n",
    "map_TMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(coord_df.shape[0]):\n",
    "    (lat, long) = coord_df.ix[i,['Latitude','Longitude']]\n",
    "    print(lat, long, 'Area with bats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(coord1_df.shape[0]):\n",
    "    (lat, long) = coord1_df.ix[i,['Latitude','Longitude']]\n",
    "    print(lat, long, 'Area with bats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# The radius is in pixels, using the absolute size value directly.\n",
    "# This code iterates through the index for Carparking_df, \n",
    "# creating a marker for each row.\n",
    "for i in range(coord_df.shape[0]):\n",
    "    (lat, long) = coord_df.ix[i,['Latitude','Longitude']]\n",
    "    map_TMA.polygon_marker(location=[lat, long], radius=5,\n",
    "                              popup='Area with bats.', \n",
    "                              line_color='blue', fill_color='#132b5e', \n",
    "                               fill_opacity=0.5)\n",
    "\n",
    "map_TMA.render_iframe = True\n",
    "# This will not display a map if your are offline. \n",
    "map_TMA.create_map(path='data/bats.html')\n",
    "map_TMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# The radius is in pixels, using the absolute size value directly.\n",
    "# This code iterates through the index for Carparking_df, \n",
    "# creating a marker for each row.\n",
    "for i in range(coord1_df.shape[0]):\n",
    "    (lat, long) = coord1_df.ix[i,['Latitude','Longitude']]\n",
    "    map_TMA.polygon_marker(location=[lat, long], radius=5,\n",
    "                              popup='Area with bats.', \n",
    "                              line_color='blue', fill_color='#132b5e', \n",
    "                               fill_opacity=0.5)\n",
    "\n",
    "map_TMA.render_iframe = True\n",
    "# This will not display a map if your are offline. \n",
    "map_TMA.create_map(path='data/batsroost.html')\n",
    "map_TMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hib_df['Latitude'] = coord_df.Latitude\n",
    "hib_df['Longitude'] = coord_df.Longitude\n",
    "hib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bat_df['Latitude'] = coord1_df.Latitude\n",
    "bat_df['Longitude'] = coord1_df.Longitude\n",
    "bat_df\n",
    "#coord1_df['name']= r_df['commonName']\n",
    "#coord1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Try to classify based on latitude and date with the column to classify as commonName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Looping to add map data:\n",
    "for i in range(coord_df.shape[0]):\n",
    "    (lat, long) = coord_df.ix[i,['Latitude','Longitude']]\n",
    "    print(lat, long, 'Area with bats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Looping to add map data:\n",
    "for i in range(coord1_df.shape[0]):\n",
    "    (lat, long) = coord1_df.ix[i,['Latitude','Longitude']]\n",
    "    print(lat, long, 'Area with bats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# let's use the pop-up string on simple_markers to report number of bats.\n",
    "#add markers, one for bats in each area \n",
    "# creating a marker for each.\n",
    "for i in range(coord_df.shape[0]):\n",
    "    Bats = coord_df['name'][i]\n",
    "    Popstring = ('Bat Type ' + Bats)\n",
    "    (lat, long) = coord_df.ix[i,['Latitude','Longitude']]\n",
    "    map_TMA.simple_marker(location=[lat, long], popup=Popstring)\n",
    "map_TMA.render_iframe = True\n",
    "# This will not display a map if your are offline. \n",
    "map_TMA.create_map(path='data/bats.html')\n",
    "map_TMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's use the pop-up string on simple_markers to report number of bats.\n",
    "#add markers, one for bats in each area \n",
    "# creating a marker for each.\n",
    "for i in range(coord1_df.shape[0]):\n",
    "    Bats = coord1_df['name'][i]\n",
    "    Popstring = ('Bat Type ' + Bats)\n",
    "    (lat, long) = coord1_df.ix[i,['Latitude','Longitude']]\n",
    "    map_TMA.simple_marker(location=[lat, long], popup=Popstring)\n",
    "map_TMA.render_iframe = True\n",
    "# This will not display a map if your are offline. \n",
    "map_TMA.create_map(path='data/batsroost.html')\n",
    "map_TMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Get the numbers of different types of bats and make new coloured markers for each type usinf folium notebook 5.2.\n",
    "# Create our base map, centred on Milton Keynes.\n",
    "# LicenceMap4 = folium.Map(location = [52.0218,-0.7599], width=500, height=500,\n",
    "#                     zoom_start=10, max_zoom=15)\n",
    "\n",
    "\n",
    "# LicenceMap4.geo_json(geo_path='data/mk.geoJSON.txt', \n",
    "#                      data_out='map-output-files/MKdata4.json',\n",
    "#                      data=licences2_df, \n",
    "#                      columns=['outcode', 'fullpercentage'], \n",
    "#                      key_on='feature.properties.Name',\n",
    "#                      fill_color='RdPu', fill_opacity=0.8, line_opacity=0.9,\n",
    "#                      legend_name='Full license percentages',\n",
    "#                      threshold_scale=[40,50,60,70,80,90]  )\n",
    "\n",
    "# LicenceMap4.render_iframe = True\n",
    "# # Note that for some reason Cholorpleth maps only works if the output file for the map\n",
    "# # is in the Notebook directory.\n",
    "# # This will not display a map if your are offline. \n",
    "# LicenceMap4.create_map(path='LicenceMap4.html')\n",
    "# LicenceMap4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "# We're going to build the legend patch list one element at a time;\n",
    "# it starts empty.\n",
    "legendpatch_list = []\n",
    "colours = {'Soprano Pipistrelle':'red', 'Common Pipistrelle':'red', \"Brandt's Bat\":'red',\n",
    "       'Western Barbastelle':'red', 'Pipistrelle':'red', 'Brown Long-eared Bat':'red',\n",
    "       \"Daubenton's Bat\":'red', 'Bat':'red', 'Serotine':'red', 'Greater Horseshoe Bat':'red',\n",
    "       'Grey Long-eared Bat':'red', 'Long-eared Bat species':'red',\n",
    "       'Lesser Horseshoe Bat':'red', \"Bechstein's Bat\":'red', \"Whiskered/Brandt's Bat\":'red',\n",
    "       \"Natterer's Bat\":'red', 'Mouse-eared Bat':'red', 'Lesser Noctule':'red',\n",
    "       'Whiskered Bat':'red', 'Myotis Bat species':'red', 'Noctule Bat':'red'}\n",
    "# We want to loop for each Region\n",
    "grouped = newer_df.groupby('commonName')\n",
    "for key, group in grouped:\n",
    "    \n",
    "#for key, group in newer_df:\n",
    "    # for each type create the legend patch\n",
    "    legendpatch_list = legendpatch_list+([mpatches.Patch(color=colours[key], label=key)]) \n",
    "\n",
    "group.plot.scatter(ax=ax,x='years', y='Count', s=(group['Count']), c=colours[key])\n",
    "#can't use common name on y because it isn't numeric you idiot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "# We're going to build the legend patch list one element at a time;\n",
    "# it starts empty.\n",
    "legendpatch_list = []\n",
    "colours = {'Soprano Pipistrelle':'red', 'Common Pipistrelle':'red', \"Brandt's Bat\":'red',\n",
    "       'Western Barbastelle':'red', 'Pipistrelle':'red', 'Brown Long-eared Bat':'red',\n",
    "       \"Daubenton's Bat\":'red', 'Bat':'red', 'Serotine':'red', 'Greater Horseshoe Bat':'red',\n",
    "       'Grey Long-eared Bat':'red', 'Long-eared Bat species':'red',\n",
    "       'Lesser Horseshoe Bat':'red', \"Bechstein's Bat\":'red', \"Whiskered/Brandt's Bat\":'red',\n",
    "       \"Natterer's Bat\":'red', 'Mouse-eared Bat':'red', 'Lesser Noctule':'red',\n",
    "       'Whiskered Bat':'red', 'Myotis Bat species':'red', 'Noctule Bat':'red'}\n",
    "# We want to loop for each Region\n",
    "#grouped = tidyfull_df.groupby('Region')\n",
    "#for key, group in grouped:\n",
    "for key in colours:\n",
    "    # for each type create the legend patch\n",
    "    legendpatch_list = legendpatch_list+([mpatches.Patch(color=colours[key], label=key)]) \n",
    "legendpatch_list\n",
    "plt.scatter(newer_df.years, newer_df.Count, s=newer_df.Count, c=colours[key])\n",
    "#can't use common name on y because it isn't numeric you idiot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "newer_df = new_df[['commonName','years','Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "newer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hmmm = battier.reset_index()\n",
    "hmmm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hmmm.plot.scatter(x='years', y='Count', c='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "grouped = newer_df.groupby(['commonName', 'years'])\n",
    "grouped.reset_index()\n",
    "grouped .plot.scatter(x='years', y='Count', logx=True,\n",
    "                         s=(grouped['Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plt.subplots() creates a plotting object that can accept \n",
    "# multiple plots, this is embedded in a single figure.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#This should work, don't cnahge\n",
    "\n",
    "# Set up the colour dict for each region:\n",
    "\n",
    "colours = {'Soprano Pipistrelle':'red', 'Common Pipistrelle':'red', \"Brandt's Bat\":'red',\n",
    "       'Western Barbastelle':'red', 'Pipistrelle':'red', 'Brown Long-eared Bat':'red',\n",
    "       \"Daubenton's Bat\":'red', 'Bat':'red', 'Serotine':'red', 'Greater Horseshoe Bat':'red',\n",
    "       'Grey Long-eared Bat':'red', 'Long-eared Bat species':'red',\n",
    "       'Lesser Horseshoe Bat':'red', \"Bechstein's Bat\":'red', \"Whiskered/Brandt's Bat\":'red',\n",
    "       \"Natterer's Bat\":'red', 'Mouse-eared Bat':'red', 'Lesser Noctule':'red',\n",
    "       'Whiskered Bat':'red', 'Myotis Bat species':'red', 'Noctule Bat':'red'}\n",
    "\n",
    "# We're going to be responsibile for our own legend, so we need \n",
    "# mpatches again.\n",
    "import matplotlib.patches as mpatches\n",
    "# We're going to build the legend patch list one element at a time;\n",
    "# it starts empty.\n",
    "legendpatch_list = []\n",
    "\n",
    "# We want to loop for each Region\n",
    "#grouped = tidyfull_df.groupby('Region')\n",
    "#for key, group in grouped:\n",
    "for key, group in grouped:\n",
    "    # for each typecreate the legend patch\n",
    "    legendpatch_list = legendpatch_list+([mpatches.Patch(color=colours[key], label=key)]) \n",
    "    # and plot the data, explicitly telling plot() that the \n",
    "    # axes object to plot on is the same axes object created \n",
    "    # using the .subplot() so, ax=ax is used each time.\n",
    "    grouped.plot.scatter(ax=ax,x='years', y='Count',\n",
    "                       logx=True,\n",
    "                       s=(group['commonName']),\n",
    "                        c=colours[key],\n",
    "                        ylim=[35,90],\n",
    "                        figsize=(8,5))\n",
    "    \n",
    "#plt.xticks(['1960','1970','1980','1990','2000','2010','2020'])             \n",
    "\n",
    "# The original x and y axes labels:\n",
    "plt.xlabel('Years by decade')\n",
    "plt.ylabel('Total Count')\n",
    "\n",
    "plt.savefig('data/batscrazy.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def randrange(n, vmin, vmax):\n",
    "    return (vmax - vmin)*np.random.rand(n) + vmin\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "n = 100\n",
    "for c, m, zl, zh in [('r', 'o', -50, -25), ('b', '^', -30, -5)]:\n",
    "    xs = randrange(n, 23, 32)\n",
    "    ys = randrange(n, 0, 100)\n",
    "    zs = randrange(n, zl, zh)\n",
    "    ax.scatter(xs, ys, zs, c=c, marker=m)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "! pip install plotly --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "print (__version__ )# requires version >= 1.9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "py.sign_in('monette', '627y9m8o6b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x, y, z = np.random.multivariate_normal(np.array([0,0,0]), np.eye(3), 200).transpose()\n",
    "trace1 = go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        line=dict(\n",
    "            color='rgba(256, 256, 226, 0.74)',\n",
    "            width=0.5\n",
    "        ),\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "x2, y2, z2 = np.random.multivariate_normal(np.array([0,0,0]), np.eye(3), 200).transpose()\n",
    "trace2 = go.Scatter3d(\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    z=z2,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='rgb(50, 50, 50)',\n",
    "        size=12,\n",
    "        symbol='circle',\n",
    "        line=dict(\n",
    "            color='rgb(204, 204, 204)',\n",
    "            width=1\n",
    "        ),\n",
    "        opacity=0.9\n",
    "    )\n",
    ")\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='simple-3d-scatter')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
