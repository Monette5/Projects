{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# This Notebook uses the following libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psqlg\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# This line suppresses a warning about a future deprecation in\n",
    "# the KNeighborsClassifier functions; you should ignore it\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "RoostCoords = pd.read_csv('data/RoostCoords.csv')\n",
    "RoostCoords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "roostyear = RoostCoords.loc[RoostCoords['year']==2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "HibernationCoords = pd.read_csv('data/HibernationCoords.csv')\n",
    "HibernationCoords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hibyear = HibernationCoords.loc[HibernationCoords['year']==2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Select a value of k to examine.\n",
    "Step 2: Select one of the n training data points as the validation data. The remaining n-1 data points are used as a training set.\n",
    "Step 3: Build a k-NN classifier with the n-1 training data points, and use this to predict the class of the validation data point. Check the predicted class against the actual class of the test data.\n",
    "Step 4: Repeat Steps 2 and 3 for each of the n labelled data points by choosing a different data point as validation data and using the rest of the n-1 data instances as training data.\n",
    "Step 5: Calculate an error rate as a ratio of incorrect classifications (f) to the total number of points in the test dataset (n), i.e. error rate = f/n.\n",
    "Step 6: With a different value of k, repeat Steps 2 to 5. Repeat this step until all values of k are examined.\n",
    "Step 7: Choose the value of k with the lowest error rate as an empirical optimal value. If there is a tie, choose the smallest k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of implementing the leave-one-out algorithm here is best carried out in two stages.\n",
    "For stage 1, we will develop a function which takes a single member of a dataset, and uses the remaining data to classify it with the k-NN algorithm.\n",
    "For stage 2, we will develop a second function which uses the function from stage 1 to calculate how many members of the dataset were correctly classified.\n",
    "We have provided a description of the working function, and suggested solutions for both these two stages, which you can use. However, you will gain much more benefit if you attempt to write the function yourself before looking at our proposed solution, even if you do not manage to build complete working functions yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def classify_single_case(trainingData_df, targetValues_ss, ix, k):\n",
    "    '''Use k-NN to classify the member of trainingData_df with index\n",
    "       ix using a k-nearest neighbours classifier. The classifier is\n",
    "       trained on the data in trainingData_df and the classes in\n",
    "       targetValues_ss, with the data point indexed by ix omitted.\n",
    "       Returns the class assigned to the data point with index ix.\n",
    "    '''\n",
    "\n",
    "    # Create a classifier instance to do k-nearest neighbours\n",
    "    myClassifier = KNeighborsClassifier(n_neighbors=k,\n",
    "                                        metric='euclidean',\n",
    "                                        weights='uniform')\n",
    "\n",
    "    # Now apply the classifier to all data points except\n",
    "    # the one indexed by ix\n",
    "    myClassifier.fit(trainingData_df.drop(ix, axis='index'),\n",
    "                     targetValues_ss.drop(ix))\n",
    "\n",
    "    # Return the class predicted by the trained classifier:\n",
    "\n",
    "    return myClassifier.predict(trainingData_df.loc[ix])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The use of latitude and longitude for the classifier wasn't proving to be reliable and as such I amended the data to use coordinates instead to see if that improved matters. However this provided poorer results and instead I will try some iterations to see if it improves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://test:test@localhost:5432/tm351test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "conn = pg.connect(dbname='tm351test', host='localhost', user='test', password='test', port=5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dfh = pd.read_sql_query('select * from HibernationBats',conn)\n",
    "dfh.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dfr = pd.read_sql_query('select * from RoostBats',conn)\n",
    "dfr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dfr1 = pd.read_sql_query(\"select * from RoostBats\\nWHERE RoostBats.year = '2010';\",conn)\n",
    "dfr1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "nobatsr = dfr1.loc[dfr1['commonname'] != 'Bat']\n",
    "nobatsr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#nobatr = hibyear.loc[hibyear['commonName'] != 'Bat']\n",
    "#nobatr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Predict the class of the data point with index 17, using a k-NN classifier\n",
    "with k=3\n",
    "\n",
    "The actual class of the data point with this index is 'Lesser Horseshoe Bat'\n",
    "\n",
    "'''\n",
    "\n",
    "# Use the two columns 'Exercise time (hours)' and \n",
    "# 'Sleep time (hours)' for the training data\n",
    "trainingData_df = dfr[['latitude', 'longitude']]\n",
    "\n",
    "# Use the column 'Patient group' as the target values\n",
    "targetValues_ss = dfr['commonname']\n",
    "\n",
    "# Return the predicted value of the data point with index 17 for k=3:\n",
    "classify_single_case(trainingData_df,\n",
    "                     targetValues_ss,\n",
    "                     17,\n",
    "                     3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(nobatsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function classified the data in the same way for values of k between 1 and 5, I will now try a subset of the whole dataset.\n",
    "Next, to obtain a list of predicted values for some k, apply the function classify_single_case to the training data for each data point, the predicted values for k=3 are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Predict the class of the data point with index 17, using a k-NN classifier\n",
    "with k=3\n",
    "\n",
    "The actual class of the data point with this index is 'Lesser Horseshoe Bat'\n",
    "\n",
    "'''\n",
    "\n",
    "# Use the two columns 'Exercise time (hours)' and \n",
    "# 'Sleep time (hours)' for the training data\n",
    "trainingData_df1 = dfr1[['latitude', 'longitude']]\n",
    "\n",
    "# Use the column 'Patient group' as the target values\n",
    "targetValues_ss1 = dfr1['commonname']\n",
    "\n",
    "# Return the predicted value of the data point with index 17 for k=3:\n",
    "classify_single_case(trainingData_df1,\n",
    "                     targetValues_ss1,\n",
    "                     17,\n",
    "                     3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "[classify_single_case(trainingData_df1,\n",
    "                      targetValues_ss1,\n",
    "                      i,\n",
    "                      3)\n",
    " for i in trainingData_df1.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the number of discrepencies between the predicted values and the actual values, compare the Series of predicted classes with the Series of actual classes (where True means the predicted class is the same as the actual class, and False means that they are different):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "[classify_single_case(trainingData_df1,\n",
    "                      targetValues_ss1,\n",
    "                      i,\n",
    "                      3)\n",
    " for i in trainingData_df1.index] == targetValues_ss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "list([classify_single_case(trainingData_df1,\n",
    "                           targetValues_ss1,\n",
    "                           i,\n",
    "                           3)\n",
    "      for i in trainingData_df1.index] == targetValues_ss1).count(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimum value of k we want the value that gets the prediction correct most often. To determine this value, carry out the above calculation for a range of values of k values from 1 to 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for k in range(1, 15):\n",
    "    print('{}\\t{}'.format(k,\n",
    "                          list([classify_single_case(trainingData_df1,\n",
    "                                                     targetValues_ss1,\n",
    "                                                     i,\n",
    "                                                     k)\n",
    "                                for i in trainingData_df1.index\n",
    "                               ] == targetValues_ss1\n",
    "                              ).count(True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-NN is very susceptible to outliers: some unusual or extreme points in a dataset can easily lead a classifier to misclassify a new point, or at least to classify it in an unintuitive way. For example, in Figure 20.12 a 3-nearest neighbours classifier would classify the new point (shown by a green triangle) as Class A, whereas looking at the classes independently, the new point seems to be a more natural fit with Class B than with Class A (Figure 20.13). Of course, it could be that the new point is also an outlier: perhaps the outlying points are a result of a quirk of your measuring apparatus? Or are the points accurate measurements of a case which you had not predicted, suggesting that they require further analysis? It is often the case that investigating the borderline cases can give the greatest insight into the dataâ€™s meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
